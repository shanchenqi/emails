  oss-security - Potential DoS vulnerability in CGit            Products  Openwall GNU/*/Linux   server OS Linux Kernel Runtime Guard John the Ripper   password cracker  Free & Open Source for any platform in the cloud Pro for Linux Pro for macOS  Wordlists   for password cracking passwdqc   policy enforcement  Free & Open Source for Unix Pro for Windows (Active Directory)  yescrypt   KDF & password hashing yespower   Proof-of-Work (PoW) crypt_blowfish   password hashing phpass   ditto in PHP tcb   better password shadowing Pluggable Authentication Modules scanlogd   port scan detector popa3d   tiny POP3 daemon blists   web interface to mailing lists msulogin   single user mode login php_mt_seed   mt_rand() cracker  Services Publications  Articles Presentations  Resources  Mailing lists Community wiki Source code repositories (GitHub) Source code repositories (CVSweb) File archive & mirrors How to verify digital signatures OVE IDs  What's new         Follow @Openwall on Twitter for new release announcements and other news   [<prev] [next>] [thread-next>] [day] [month] [year] [list]  Date: Sun, 19 May (CEST) From: Wire Snark <wsnark@...a.io> To:  <oss-security@...ts.openwall.com> Subject: Potential DoS vulnerability in CGit  Hello, oss-security list  I need your advice on the following bug in CGit disclosured by me recently in the cgit 'at' lists.zx2c4.com [1]. CGit is a hyperfast web frontend for git repositories written in C [2].  There is no formal security contact at [3], contacting CGit author and maintainer Jason Donenfeld directly didn't work either (probably my mail ends up in spam or whatever). My posting to CGit mailing list hasn't received a reply yet (since May 15) so I'm not sure whether someone has even read it so far.  My question: is this a valid security issue (DoS) that's worth applying for CVE? This is my first bug in public software actually, so your advice on this will be very helpful. Should I do more thorough performance measures, or this qualitative analysis below is enough?  [1] [2] https://git.zx2c4.com/cgit/ <https://git.zx2c4.com/cgit/> [3] https://git.zx2c4.com/cgit/about/ <https://git.zx2c4.com/cgit/about/>  ### Bug description  A specially crafted URL in the request is processed by cgit with a sort of non-linear(quadratic) function, excessively using CPU and network resources. That is, given input with len(input) = n, output produced by cgit becomes len(output) ~ C * n^2.  Severity: Low (?)  ### Reproducers  Hand-crafted reproducers I have come with so far look like: curl  Where is where my web server is, "mycgit" is a valid repository name, and the number of /0/ blocks that can be filled is determined by the maximum URL length configured at the particular web server.  Reproducer for my local server setup: local_repr.txt (attached) Input len = Output is  For kernel.org, that is using cgit: kernel.org_repr.txt (attached) There are 2 reproducers: - URL with bytes. Output is html with kbytes. - URL with (maximum that is accepted at kernel.org at the moment). Output is html with kbytes.  The dependency seems to be quadratic with C ~  Original hang reproducer generated by AFL: afl_repr.bin (attached) Input: 34kb, Output:  Note: afl_repr.bin file format is tab-separated values for all used env variables by cgit; the reproducer is different and contains some non-printable chars (in my fuzzing setup cgit reads env variables from stdin, allowing arbitrary input)  ### Analysis  Backtrace from interrupting cgit during processing of this input (with output in terminal, i.e. slow): Program received signal SIGINT, Interrupt. in write () from /usr/lib/libpthread.so.0 (gdb) bt #0  in write () from /usr/lib/libpthread.so.0 #1  in html_raw (data=<optimized out>, at ../html.c:83 #2  in html (txt=<optimized out>) at #3  html_url_path (txt=<optimized out>, "Oe", '/' <repeats times>...)     at #4  in repolink (title=title@...ry=0x0, class=class@...ry=0x0,     "tree", "fuzzing",     "Oe", '/' <repeats times>...) at #5  in reporevlink "tree",     "", title=title@...ry=0x0, class=class@...ry=0x0,     "fuzzing", rev=0x0,     "Oe", '/' <repeats times>...) at #6  in cgit_tree_link "Oe", '/' <repeats times>...,     rev=<optimized out>, head=<optimized out>, class=0x0, title=0x0, "")     at #7  cgit_self_link "", class=0x0, title=0x0) at #8  in cgit_print_path_crumbs (path=<optimized out>) at #9  cgit_print_pageheader () at #10 in cgit_print_layout_start () at #11 cgit_print_error_page "Not found",     "Path not found") at #12 in cgit_print_tree "fuzzing",     "Oe", '/' <repeats times>...) at #13 in process_request () at #14 in cache_process (size=<optimized out>, path=<optimized out>,     key=<optimized out>, ttl=<optimized out>, <process_request>)     at #15 in cmd_main (argc=<optimized out>, argv=<optimized out>) at #16 in main (argc=2, at common-main.c:45  As I understand, the issue is in ui-shared.c, cgit_print_path_crumbs():  ctx.qry.path = p = path; while (p < end) {   if (!(q = strchr(p, '/')))     q = end;   *q = '\0';   html_txt("/");   cgit_self_link(p, NULL, NULL);   if (q < end)     *q = '/';   p = q + 1; }  It attempts to print a cgit_self_link() on each subpath in the URL, resulting in O(n^2) for n as number of subpaths in the url.  ### How to fix  I don't really know cgit internals, so I can propose only very simple fix - limit the depth of path crumbs handling, e.g.  diff --git a/ui-shared.c b/ui-shared.c index --- a/ui-shared.c +++ b/ui-shared.c @@ @@ static void cgit_print_path_crumbs(char *path)         ctx.qry.path = NULL;         cgit_self_link("root", NULL, NULL);         ctx.qry.path = p = path; -       while (p < end) { +       int maxdepth = 10; +       while (p < end && maxdepth > 0) { +               maxdepth--;                 if (!(q = strchr(p, '/')))                         q = end;                 *q = '\0';  Probably this magic 10 should be defined somewhere (do not think it should be configurable though). Also I don't know what is valid path depth expected here. With this fix I confirm the output size is reduced to normal URL gives 50K, 34K AFL-generated one gives html output).  ### Security implications  I think this issue can be leveraged to cause Denial of Service condition on the cgit server. I have tried following experiment: at the localhost start curl instances with reproducer one) and "--limit-rate 10K -sS >/dev/null" options so they do not consume output html too fast. This results in a few seconds of high CPU usage at the target server (I used 4 vCPU VM from some old Core i7 mobile CPU). curls cause load ~1, adding more can push to 2 and so on; curls do not seem to consume much CPU themselves. I use nginx, fcgiwrap and cgit.cgi, so nginx worker process and fcgiwrap were using the most of CPU, probably until all cgit output has been saved in nginx buffer (not really sure here, but seems like nginx memory usage grows). After initial CPU usage burst cgit finishes rendering and terminates, so CPU usage goes down. Some clients may receive one of the two errors:   curl: (18) transfer closed with outstanding read data remaining   curl: (56) Recv failure: Connection reset by peer  Most of the clients continued to work. Sometimes (especially if increasing a number of clients) there are fcgiwrap failures like:  [crit] pwritev() has written only of while reading upstream, client: server: localhost, request: "GET  After applying the fix, none of the issues have been observed with curl readers at the same setup (even if throttled to 1K instead of 10K as before, to keep connections open). CPU bursts only for a very short amount of time (mostly when of curls are forked/exec'd, though slight fcgiwrap CPU usage has been observed in htop too).  ### About the author  My name is Fyodor [Wire Snark], I'm an amateur security researcher at (http://defcon-nn.ru <http://defcon-nn.ru>), our local DEF CON group in Nizhniy Novgorod, Russia.  This report has been prepared as a result of my self-studying fuzzing with AFL and LibFuzzer from LLVM and applying them to cgit. I haven't seen any such fuzzing reported for cgit, so if you know any previous work on this, I'd be glad to know (I plan to publish a blog post about my fuzzing setup and these results; no crashes have been observed so far).   Best regards, Wire Snark   Powered by blists - more mailing lists  Please check out the  Open Source Software Security Wiki, which is counterpart to this mailing list.  Confused about mailing lists and their use? Read about mailing lists on Wikipedia and check out these guidelines on proper formatting of your messages.      